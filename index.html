<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Custom CNN Anti-Spoof Live</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<style>
  * {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
  }

  body {
    text-align: center;
    font-family: Arial, sans-serif;
    padding: 20px;
  }

  h2 {
    font-size: 24px;
    margin-bottom: 8px;
  }

  .subtitle {
    font-size: 14px;
    color: #666;
    margin-bottom: 20px;
  }

  .instructions {
    font-size: 14px;
    color: #444;
    max-width: 400px;
    margin: 0 auto 20px;
    line-height: 1.5;
  }

  .video-wrapper {
    position: relative;
    width: min(400px, calc(100vw - 40px));
    height: min(400px, calc(100vw - 40px));
    margin: 0 auto 20px;
    overflow: hidden;
  }

  video {
    width: 100%;
    height: 100%;
    object-fit: cover;
    transform: scaleX(-1);
    display: block;
  }

  /* Oval overlay with sharp edge */
  .video-wrapper::after {
    content: "";
    position: absolute;
    inset: 0;
    pointer-events: none;
    background:
      radial-gradient(
        ellipse 35% 55% at center,
        transparent 0%,
        transparent 90%,
        rgba(0, 0, 0, 0.85) 91%
      );
  }

  #result {
    font-size: 18px;
    font-weight: bold;
    padding: 10px;
    margin: 0 auto 8px;
  }

  .confidence {
    font-size: 14px;
    color: #666;
  }

  .model-info {
    margin-top: 20px;
    font-size: 12px;
    color: #777;
  }
</style>
</head>
<body>

<h2>Custom CNN Anti-Spoof</h2>
<p class="subtitle">Optimized 7-Block Architecture | Texture + Color Analysis</p>

<div class="instructions">
  <strong>Instructions:</strong><br>
  • Ensure good lighting (avoid harsh reflections)<br>
  • Fit your face tightly within the oval<br>
  • Hold steady for accurate detection
</div>

<div class="video-wrapper">
  <video id="video" autoplay playsinline></video>
</div>

<canvas id="canvas" width="224" height="224" style="display:none;"></canvas>

<div id="result">Loading model...</div>

<p class="confidence" id="confidence"></p>

<div class="model-info">
  <strong>Model:</strong> optimized_antispoof_cnn_int8.onnx<br>
  <strong>Architecture:</strong> Custom CNN (7 blocks + 2 branches)<br>
  <strong>Input:</strong> 224×224×3 | <strong>Inference:</strong> Real-time
</div>

<script>
let session;
let isProcessing = false;

async function init() {
  try {
    // Change this to your ONNX model filename
    session = await ort.InferenceSession.create("optimized_antispoof_cnn_int8.onnx");
    
    document.getElementById("result").innerText = 'Model loaded. Starting camera...';
    
    await startCamera();
  } catch (error) {
    document.getElementById("result").innerText = 'Error loading model';
    document.getElementById("confidence").innerText = `Error: ${error.message}`;
    console.error("Initialization error:", error);
  }
}

async function startCamera() {
  try {
    const video = document.getElementById("video");

    const stream = await navigator.mediaDevices.getUserMedia({
      video: { 
        facingMode: "user",
        width: { ideal: 640 },
        height: { ideal: 640 }
      }
    });

    video.srcObject = stream;
    
    // Wait for video to be ready
    video.onloadedmetadata = () => {
      runLoop();
    };
  } catch (error) {
    document.getElementById("result").innerText = 'Camera access denied';
    document.getElementById("confidence").innerText = 
      'Please allow camera access to use this feature';
    console.error("Camera error:", error);
  }
}

async function runLoop() {
  if (isProcessing) {
    requestAnimationFrame(runLoop);
    return;
  }

  isProcessing = true;

  try {
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    // Mirror the video horizontally for natural selfie view
    ctx.save();
    ctx.scale(-1, 1);
    ctx.drawImage(video, -224, 0, 224, 224);
    ctx.restore();

    // Extract image data
    const imageData = ctx.getImageData(0, 0, 224, 224).data;
    const floatData = new Float32Array(1 * 3 * 224 * 224);

    // Normalize using ImageNet stats (same as training)
    const mean = [0.485, 0.456, 0.406];
    const std  = [0.229, 0.224, 0.225];

    for (let i = 0; i < 224 * 224; i++) {
      const r = imageData[i * 4]     / 255;
      const g = imageData[i * 4 + 1] / 255;
      const b = imageData[i * 4 + 2] / 255;

      floatData[i]             = (r - mean[0]) / std[0];
      floatData[i + 224*224]   = (g - mean[1]) / std[1];
      floatData[i + 2*224*224] = (b - mean[2]) / std[2];
    }

    // Create tensor and run inference
    const tensor = new ort.Tensor("float32", floatData, [1, 3, 224, 224]);
    const results = await session.run({ input: tensor });

    // Get prediction
    const logit = results.output.data[0];
    const prob = 1 / (1 + Math.exp(-logit)); // Sigmoid

    // Update UI
    const resultDiv = document.getElementById("result");
    const confidenceDiv = document.getElementById("confidence");
    
    if (prob > 0.5) {
      // REAL
      resultDiv.innerText = 'REAL FACE';
      confidenceDiv.innerText = `Confidence: ${(prob * 100).toFixed(1)}%`;
    } else {
      // ATTACK
      resultDiv.innerText = 'SPOOF DETECTED';
      confidenceDiv.innerText = `Confidence: ${((1 - prob) * 100).toFixed(1)}%`;
    }

  } catch (error) {
    console.error("Inference error:", error);
    document.getElementById("result").innerText = 'Inference error';
    document.getElementById("confidence").innerText = error.message;
  }

  isProcessing = false;
  requestAnimationFrame(runLoop);
}

// Start initialization when page loads
init();
</script>

</body>
</html>
