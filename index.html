<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Anti-Spoof Live</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
<style>
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body {
    text-align: center;
    font-family: Arial;
    overflow-x: hidden;
    background: #111;
    color: #eee;
  }
  h2 { font-size: 30px; margin: 16px 0 6px; color: #fff; }
  .instructions {
    font-size: 15px;
    color: #aaa;
    max-width: 360px;
    margin: 8px auto 16px;
    line-height: 1.4;
    padding: 0 12px;
  }

  /* Original wrapper sizing — untouched */
  .video-wrapper {
    position: relative;
    width: min(400px, calc(100vw - 24px));
    height: min(400px, calc(100vw - 24px));
    margin: 0 auto;
    overflow: hidden;
  }

  video {
    width: 100%;
    height: 100%;
    object-fit: cover;
    transform: scaleX(-1);
    display: block;
  }

  /* Original CSS oval mask */
  .video-wrapper::after {
    content: "";
    position: absolute;
    inset: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse 35% 55% at center,
      transparent 0%,
      transparent 90%,
      rgba(0,0,0,0.80) 91%
    );
  }

  /* Debug canvas — overlays video, same bounds, above the mask */
  #debugCanvas {
    position: absolute;
    inset: 0;
    width: 100%;
    height: 100%;
    pointer-events: none;
    z-index: 3;
  }

  #statusPill {
    position: absolute;
    bottom: 14px;
    left: 50%;
    transform: translateX(-50%);
    z-index: 4;
    font-size: 12px;
    padding: 5px 14px;
    border-radius: 100px;
    background: rgba(0,0,0,0.75);
    border: 1px solid #555;
    color: #aaa;
    white-space: nowrap;
    transition: color 0.25s, border-color 0.25s;
  }
  #statusPill.aligned { color: #00e5a0; border-color: #00e5a0; }

  #captureBtn {
    display: none;
    margin: 16px auto 0;
    padding: 13px 40px;
    font-size: 16px;
    font-weight: bold;
    background: #00e5a0;
    color: #111;
    border: none;
    border-radius: 10px;
    cursor: pointer;
  }
  #captureBtn.visible { display: inline-block; }
  #captureBtn:disabled { background: #333; color: #666; cursor: not-allowed; }

  #result {
    margin-top: 14px;
    font-size: 18px;
    min-height: 28px;
    color: #ccc;
  }
  #result.real   { color: #00e5a0; font-weight: bold; }
  #result.attack { color: #ff6b6b; font-weight: bold; }

  #inferCanvas { display: none; }
</style>
</head>
<body>

<h2>Live Anti-Spoof</h2>
<p class="instructions">
  • Good lighting, face clearly visible.<br>
  • Fit your face tightly inside the oval — green outline = ready.
</p>

<div class="video-wrapper" id="wrapper">
  <video id="video" autoplay playsinline></video>
  <canvas id="debugCanvas"></canvas>
  <div id="statusPill">Looking for face…</div>
</div>

<canvas id="inferCanvas" width="224" height="224"></canvas>
<button id="captureBtn">Capture &amp; Verify</button>
<p id="result">Loading model…</p>

<script>
// ─────────────────────────────────────────────────────────
//  OVAL — must match the CSS radial-gradient exactly:
//    ellipse 35% 55% at center
//  → rx = 35% of wrapper width,  ry = 55% of wrapper height
//  In normalised coords (0-1): cx=0.5, cy=0.5, rx=0.35, ry=0.55
// ─────────────────────────────────────────────────────────
const OX = 0.50, OY = 0.50, ORX = 0.35, ORY = 0.55;

function inOval(nx, ny) {
  const dx = (nx - OX) / ORX;
  const dy = (ny - OY) / ORY;
  return dx * dx + dy * dy <= 1.0;
}

// ── DOM ──
const video       = document.getElementById("video");
const wrapper     = document.getElementById("wrapper");
const debugCanvas = document.getElementById("debugCanvas");
const dctx        = debugCanvas.getContext("2d");
const statusPill  = document.getElementById("statusPill");
const captureBtn  = document.getElementById("captureBtn");
const resultEl    = document.getElementById("result");
const inferCanvas = document.getElementById("inferCanvas");
const ictx        = inferCanvas.getContext("2d");

let session     = null;
let faceAligned = false;
let running     = false;

// ── Keep debug canvas sized to the wrapper ──
function syncCanvas() {
  debugCanvas.width  = wrapper.offsetWidth;
  debugCanvas.height = wrapper.offsetHeight;
}
new ResizeObserver(syncCanvas).observe(wrapper);

// ── Load ONNX model ──
async function loadModel() {
  for (const name of ["optimized_antispoof_cnn_int8.onnx", "antispoof_model.onnx"]) {
    try {
      session = await ort.InferenceSession.create(name);
      console.log("Model loaded:", name);
      resultEl.textContent = "Ready — align your face.";
      return;
    } catch(_) {}
  }
  resultEl.textContent = "No model found (place .onnx here).";
}

// ── MediaPipe ──
function startDetection() {
  syncCanvas();
  const fd = new FaceDetection({
    locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${f}`
  });
  fd.setOptions({ model: "short", minDetectionConfidence: 0.5 });
  fd.onResults(onResults);

  const cam = new Camera(video, {
    onFrame: async () => { await fd.send({ image: video }); },
    width: 640, height: 480
  });
  cam.start();
}

// ── Per-frame result handler ──
function onResults(results) {
  const W = debugCanvas.width;
  const H = debugCanvas.height;
  dctx.clearRect(0, 0, W, H);

  // Always draw the oval so user can see where to aim
  drawOval(W, H);

  if (!results.detections || results.detections.length === 0) {
    setAligned(false, "No face detected");
    return;
  }

  const det = results.detections[0];
  const bb  = det.boundingBox;
  // MediaPipe NormalizedRect: xCenter, yCenter, width, height (all 0-1, unmirrored)
  // Video is CSS mirrored → flip x:  mirroredX = 1 - x
  const bCX  = 1 - bb.xCenter;
  const bCY  = bb.yCenter;
  const bW   = bb.width;
  const bH   = bb.height;

  const fL = bCX - bW / 2;
  const fR = bCX + bW / 2;
  const fT = bCY - bH / 2;
  const fB = bCY + bH / 2;

  // ── Tight-fit test ──
  // All 4 corners inside oval
  const cornersIn = inOval(fL, fT) && inOval(fR, fT) &&
                    inOval(fL, fB) && inOval(fR, fB);

  // Face area must be ≥ 55% of oval area (close enough)
  const bigEnough = (bW * bH) >= (Math.PI * ORX * ORY * 0.55);

  const aligned = cornersIn && bigEnough;

  // ── Draw face bounding box ──
  const bx = fL * W, by = fT * H, bw2 = bW * W, bh2 = bH * H;
  dctx.strokeStyle = aligned ? "#00e5a0" : "#ff6b6b";
  dctx.lineWidth   = 2.5;
  dctx.strokeRect(bx, by, bw2, bh2);

  // Centre dot
  dctx.fillStyle = aligned ? "#00e5a0" : "#ff9944";
  dctx.beginPath();
  dctx.arc(bCX * W, bCY * H, 5, 0, Math.PI * 2);
  dctx.fill();

  // Debug label: shows exactly what checks pass/fail
  const conf  = +(det.score?.[0] ?? det.score ?? 0);
  const label = `conf:${conf.toFixed(2)}  corners:${cornersIn?"✓":"✗"}  size:${bigEnough?"✓":"✗"}`;
  dctx.font      = "11px monospace";
  dctx.fillStyle = "#fff";
  dctx.fillText(label, bx + 4, Math.max(by - 6, 12));

  // Hint text for user
  let hint = "";
  if (!cornersIn && !bigEnough) hint = "Move closer & centre";
  else if (!cornersIn)           hint = "Centre face in oval";
  else if (!bigEnough)           hint = "Move closer";
  else                           hint = "Face aligned ✓";

  setAligned(aligned, hint);
}

function drawOval(W, H) {
  dctx.save();
  dctx.beginPath();
  dctx.ellipse(OX * W, OY * H, ORX * W, ORY * H, 0, 0, Math.PI * 2);
  dctx.strokeStyle = faceAligned ? "#00e5a0" : "rgba(255,255,255,0.4)";
  dctx.lineWidth   = faceAligned ? 3 : 2;
  dctx.setLineDash(faceAligned ? [] : [8, 5]);
  dctx.stroke();
  dctx.restore();
}

function setAligned(aligned, hint) {
  faceAligned = aligned;
  statusPill.textContent = hint || (aligned ? "Face aligned ✓" : "Align your face");
  statusPill.classList.toggle("aligned", aligned);
  captureBtn.classList.toggle("visible", aligned);
}

// ── Capture & Infer ──
captureBtn.addEventListener("click", async () => {
  if (running || !faceAligned) return;
  running = true;
  captureBtn.disabled = true;
  resultEl.className  = "";
  resultEl.textContent = "Analysing… ⏳";

  ictx.save();
  ictx.scale(-1, 1);
  ictx.drawImage(video, -224, 0, 224, 224);
  ictx.restore();

  const imageData = ictx.getImageData(0, 0, 224, 224).data;
  const floatData = new Float32Array(3 * 224 * 224);
  const mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225];
  for (let i = 0; i < 224 * 224; i++) {
    floatData[i]             = (imageData[i*4]   / 255 - mean[0]) / std[0];
    floatData[i + 224*224]   = (imageData[i*4+1] / 255 - mean[1]) / std[1];
    floatData[i + 2*224*224] = (imageData[i*4+2] / 255 - mean[2]) / std[2];
  }

  await new Promise(r => setTimeout(r, 2000)); // deliberate 2s pause

  if (session) {
    try {
      const tensor = new ort.Tensor("float32", floatData, [1, 3, 224, 224]);
      const out    = await session.run({ input: tensor });
      const prob   = 1 / (1 + Math.exp(-out.output.data[0]));
      const isReal = prob > 0.5;
      resultEl.className   = isReal ? "real" : "attack";
      resultEl.textContent = isReal
        ? `✓ REAL  (${prob.toFixed(3)})`
        : `✗ SPOOF  (${(1-prob).toFixed(3)})`;
    } catch(e) {
      resultEl.textContent = "Inference error: " + e.message;
    }
  } else {
    resultEl.textContent = "No model — place .onnx in same folder.";
  }

  captureBtn.disabled = false;
  running = false;
});

// ── Boot ──
loadModel();
startDetection();
</script>
</body>
</html>
