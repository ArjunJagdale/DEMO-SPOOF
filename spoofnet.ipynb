{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14851424,"sourceType":"datasetVersion","datasetId":9499335}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q timm onnxruntime onnxscript","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:27:36.302040Z","iopub.execute_input":"2026-02-16T06:27:36.302337Z","iopub.status.idle":"2026-02-16T06:27:42.979962Z","shell.execute_reply.started":"2026-02-16T06:27:36.302311Z","shell.execute_reply":"2026-02-16T06:27:42.979218Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:27:47.387141Z","iopub.execute_input":"2026-02-16T06:27:47.387670Z","iopub.status.idle":"2026-02-16T06:27:55.580674Z","shell.execute_reply.started":"2026-02-16T06:27:47.387638Z","shell.execute_reply":"2026-02-16T06:27:55.579879Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ---------------------------\n# Reproducibility\n# ---------------------------\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:28:00.205741Z","iopub.execute_input":"2026-02-16T06:28:00.206618Z","iopub.status.idle":"2026-02-16T06:28:00.216807Z","shell.execute_reply.started":"2026-02-16T06:28:00.206587Z","shell.execute_reply":"2026-02-16T06:28:00.216094Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:28:07.907284Z","iopub.execute_input":"2026-02-16T06:28:07.907589Z","iopub.status.idle":"2026-02-16T06:28:07.972898Z","shell.execute_reply.started":"2026-02-16T06:28:07.907561Z","shell.execute_reply":"2026-02-16T06:28:07.972034Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ---------------------------\n# Kaggle Dataset Paths\n# ---------------------------\nTRAIN_REAL   = os.path.join(\"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/train/real\")\nTRAIN_ATTACK = os.path.join(\"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/train/attack\")\nTEST_REAL    = os.path.join(\"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/test/real\")\nTEST_ATTACK  = os.path.join(\"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/test/attack\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:32:25.016824Z","iopub.execute_input":"2026-02-16T06:32:25.017587Z","iopub.status.idle":"2026-02-16T06:32:25.021480Z","shell.execute_reply.started":"2026-02-16T06:32:25.017553Z","shell.execute_reply":"2026-02-16T06:32:25.020761Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# ---------------------------\n# Dataset\n# ---------------------------\nclass AntispoofDataset(Dataset):\n    def __init__(self, real_path, attack_path, transform=None):\n        self.samples = []\n        self.transform = transform\n\n        # Real = 1\n        for identity in os.listdir(real_path):\n            identity_path = os.path.join(real_path, identity)\n            if os.path.isdir(identity_path):\n                for img in os.listdir(identity_path):\n                    if img.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n                        self.samples.append((os.path.join(identity_path, img), 1))\n\n        # Attack = 0\n        for identity in os.listdir(attack_path):\n            identity_path = os.path.join(attack_path, identity)\n            if os.path.isdir(identity_path):\n                for img in os.listdir(identity_path):\n                    if img.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n                        self.samples.append((os.path.join(identity_path, img), 0))\n\n        real_count = sum(1 for _, label in self.samples if label == 1)\n        attack_count = len(self.samples) - real_count\n        print(f\"Loaded {len(self.samples)} frames  - \\nReal: {real_count} | Attack: {attack_count}\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, torch.tensor(label, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:56:30.012238Z","iopub.execute_input":"2026-02-16T06:56:30.013099Z","iopub.status.idle":"2026-02-16T06:56:30.021091Z","shell.execute_reply.started":"2026-02-16T06:56:30.013049Z","shell.execute_reply":"2026-02-16T06:56:30.020322Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# ---------------------------\n# Transforms - HEAVY augmentation for small dataset\n# ---------------------------\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n    transforms.RandomRotation(15),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:56:39.502915Z","iopub.execute_input":"2026-02-16T06:56:39.503503Z","iopub.status.idle":"2026-02-16T06:56:39.509293Z","shell.execute_reply.started":"2026-02-16T06:56:39.503473Z","shell.execute_reply":"2026-02-16T06:56:39.508349Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"train_dataset = AntispoofDataset(TRAIN_REAL, TRAIN_ATTACK, train_transform)\ntest_dataset  = AntispoofDataset(TEST_REAL, TEST_ATTACK, test_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:56:51.585010Z","iopub.execute_input":"2026-02-16T06:56:51.585621Z","iopub.status.idle":"2026-02-16T06:56:52.055422Z","shell.execute_reply.started":"2026-02-16T06:56:51.585589Z","shell.execute_reply":"2026-02-16T06:56:52.054656Z"}},"outputs":[{"name":"stdout","text":"Loaded 2806 frames  - \nReal: 1333 | Attack: 1473\nLoaded 1302 frames  - \nReal: 637 | Attack: 665\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# INCREASED BATCH SIZE: 32 → 64 for more stable gradients\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\ntest_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:56:59.225177Z","iopub.execute_input":"2026-02-16T06:56:59.225898Z","iopub.status.idle":"2026-02-16T06:56:59.230981Z","shell.execute_reply.started":"2026-02-16T06:56:59.225866Z","shell.execute_reply":"2026-02-16T06:56:59.230078Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# ---------------------------\n# Building Blocks\n# ---------------------------\nclass DepthwiseSeparableConv(nn.Module):\n    \"\"\"\n    Depthwise Separable Convolution (MobileNet-style)\n    Reduces parameters while maintaining expressiveness\n    \"\"\"\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels,kernel_size=3, stride=stride, padding=1,groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:57:43.033335Z","iopub.execute_input":"2026-02-16T06:57:43.033860Z","iopub.status.idle":"2026-02-16T06:57:43.039636Z","shell.execute_reply.started":"2026-02-16T06:57:43.033831Z","shell.execute_reply":"2026-02-16T06:57:43.038840Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    \"\"\"\n    Residual Block with Depthwise Separable Convs\n    Skip connection for better gradient flow\n    \"\"\"\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = DepthwiseSeparableConv(channels, channels, stride=1)\n        self.conv2 = nn.Sequential(nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),nn.BatchNorm2d(channels))\n        self.relu = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out += residual  # Skip connection\n        out = self.relu(out)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:57:55.954716Z","iopub.execute_input":"2026-02-16T06:57:55.955375Z","iopub.status.idle":"2026-02-16T06:57:55.960561Z","shell.execute_reply.started":"2026-02-16T06:57:55.955347Z","shell.execute_reply":"2026-02-16T06:57:55.959813Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# ---------------------------\n# Optimized Custom CNN Model\n# ---------------------------\nclass OptimizedAntispoofCNN(nn.Module):\n    \"\"\"\n    Optimized Custom CNN for Antispoofing\n    \n    KEY IMPROVEMENTS:\n    1. Deeper backbone: 7 blocks (vs 5)\n    2. Depthwise separable convolutions (fewer params)\n    3. Residual connections (better gradient flow)\n    4. 2 specialized branches: Texture + Color only\n    5. Reduced regularization (dropout 0.2 vs 0.4)\n    \n    Architecture designed for small dataset (4K samples)\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        \n        # ============================================\n        # STEM: Initial feature extraction\n        # ============================================\n        # Input: 224x224x3 → 112x112x32\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True)\n        )\n        \n        # ============================================\n        # BACKBONE: 7-Block Feature Extractor\n        # ============================================\n        \n        # Block 1: 112x112x32 → 112x112x32 (with residual)\n        self.block1 = nn.Sequential(\n            ResidualBlock(32),\n            ResidualBlock(32)\n        )\n        \n        # Block 2: 112x112x32 → 56x56x64\n        self.block2 = nn.Sequential(\n            DepthwiseSeparableConv(32, 64, stride=2),\n            ResidualBlock(64)\n        )  # → TEXTURE BRANCH INPUT\n        \n        # Block 3: 56x56x64 → 28x28x128\n        self.block3 = nn.Sequential(\n            DepthwiseSeparableConv(64, 128, stride=2),\n            ResidualBlock(128)\n        )\n        \n        # Block 4: 28x28x128 → 28x28x128 (with residual)\n        self.block4 = nn.Sequential(\n            ResidualBlock(128),\n            ResidualBlock(128)\n        )  # → COLOR BRANCH INPUT\n        \n        # Block 5: 28x28x128 → 14x14x256\n        self.block5 = nn.Sequential(\n            DepthwiseSeparableConv(128, 256, stride=2),\n            ResidualBlock(256)\n        )\n        \n        # Block 6: 14x14x256 → 7x7x512\n        self.block6 = nn.Sequential(\n            DepthwiseSeparableConv(256, 512, stride=2),\n            ResidualBlock(512)\n        )\n        \n        # Block 7: 7x7x512 → 7x7x512 (with residual)\n        self.block7 = nn.Sequential(\n            ResidualBlock(512),\n            ResidualBlock(512)\n        )\n        \n        # ============================================\n        # BRANCH 1: Texture Analysis\n        # ============================================\n        # Captures high-frequency artifacts (print dots, screen pixels)\n        # Input: 56x56x64 from block2\n        self.texture_branch = nn.Sequential(\n            # Enhance texture details\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            # Global texture descriptor\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(64, 64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2)  # REDUCED from 0.3\n        )  # Output: 64-dim\n        \n        # ============================================\n        # BRANCH 2: Color Statistics Analysis\n        # ============================================\n        # Analyzes color distribution (screens have different gamut)\n        # Input: 28x28x128 from block4\n        self.color_branch = nn.Sequential(\n            # Spatial color distribution (4x4 grid)\n            nn.Conv2d(128, 64, kernel_size=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d(4),  # 4x4 spatial grid\n            nn.Flatten(),\n            nn.Linear(64 * 4 * 4, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),  # REDUCED from 0.3\n            nn.Linear(128, 128),\n            nn.ReLU(inplace=True)\n        )  # Output: 128-dim\n        \n        # ============================================\n        # MAIN BRANCH: Deep semantic features\n        # ============================================\n        self.main_pool = nn.AdaptiveAvgPool2d(1)\n        \n        # ============================================\n        # FUSION & CLASSIFICATION\n        # ============================================\n        # Concatenate: Texture(64) + Color(128) + Main(512) = 704\n        self.classifier = nn.Sequential(\n            nn.Linear(64 + 128 + 512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),  # REDUCED from 0.4\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),  # REDUCED from 0.4\n            nn.Linear(128, 1)\n        )\n    \n    def forward(self, x):\n        # Stem\n        x = self.stem(x)  # 112x112x32\n        \n        # Backbone\n        x = self.block1(x)  # 112x112x32\n        texture_feat = self.block2(x)  # 56x56x64 → Texture Branch\n        x = self.block3(texture_feat)  # 28x28x128\n        color_feat = self.block4(x)  # 28x28x128 → Color Branch\n        x = self.block5(color_feat)  # 14x14x256\n        x = self.block6(x)  # 7x7x512\n        main_feat = self.block7(x)  # 7x7x512\n        \n        # Branch processing\n        texture_out = self.texture_branch(texture_feat)  # 64-dim\n        color_out = self.color_branch(color_feat)  # 128-dim\n        main_out = self.main_pool(main_feat).flatten(1)  # 512-dim\n        \n        # Concatenate all features\n        combined = torch.cat([texture_out, color_out, main_out], dim=1)  # 704-dim\n        \n        # Classification\n        output = self.classifier(combined)\n        \n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:58:10.004107Z","iopub.execute_input":"2026-02-16T06:58:10.004590Z","iopub.status.idle":"2026-02-16T06:58:10.019087Z","shell.execute_reply.started":"2026-02-16T06:58:10.004562Z","shell.execute_reply":"2026-02-16T06:58:10.018364Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# ---------------------------\n# Model Summary\n# ---------------------------\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:59:31.113342Z","iopub.execute_input":"2026-02-16T06:59:31.113976Z","iopub.status.idle":"2026-02-16T06:59:31.118076Z","shell.execute_reply.started":"2026-02-16T06:59:31.113947Z","shell.execute_reply":"2026-02-16T06:59:31.117175Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model = OptimizedAntispoofCNN().to(device)\nprint(f\"\\n{'='*60}\")\nprint(f\"Optimized Custom Antispoof CNN\")\nprint(f\"{'='*60}\")\nprint(f\"Architecture: 7 blocks + 2 branches (Texture + Color)\")\nprint(f\"Total Trainable Parameters: {count_parameters(model):,}\")\nprint(f\"{'='*60}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:59:45.153375Z","iopub.execute_input":"2026-02-16T06:59:45.153953Z","iopub.status.idle":"2026-02-16T06:59:45.259002Z","shell.execute_reply.started":"2026-02-16T06:59:45.153924Z","shell.execute_reply":"2026-02-16T06:59:45.258263Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nOptimized Custom Antispoof CNN\n============================================================\nArchitecture: 7 blocks + 2 branches (Texture + Color)\nTotal Trainable Parameters: 9,731,521\n============================================================\n\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# ---------------------------\n# Training Setup with Warmup\n# ---------------------------\ncriterion = nn.BCEWithLogitsLoss()\n\n# INCREASED LR: 1e-3 → 2e-3\noptimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)  # REDUCED weight decay\n\n# Cosine annealing with warmup\nNUM_EPOCHS = 35  # INCREASED from 25\nWARMUP_EPOCHS = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:00:20.336924Z","iopub.execute_input":"2026-02-16T07:00:20.337443Z","iopub.status.idle":"2026-02-16T07:00:20.342054Z","shell.execute_reply.started":"2026-02-16T07:00:20.337414Z","shell.execute_reply":"2026-02-16T07:00:20.341507Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Main scheduler (after warmup)\nmain_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, \n    T_max=NUM_EPOCHS - WARMUP_EPOCHS, \n    eta_min=1e-6\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:00:29.238873Z","iopub.execute_input":"2026-02-16T07:00:29.239493Z","iopub.status.idle":"2026-02-16T07:00:29.243263Z","shell.execute_reply.started":"2026-02-16T07:00:29.239460Z","shell.execute_reply":"2026-02-16T07:00:29.242601Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Warmup scheduler\ndef warmup_lr(epoch):\n    if epoch < WARMUP_EPOCHS:\n        return (epoch + 1) / WARMUP_EPOCHS\n    return 1.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:00:37.640592Z","iopub.execute_input":"2026-02-16T07:00:37.641304Z","iopub.status.idle":"2026-02-16T07:00:37.644848Z","shell.execute_reply.started":"2026-02-16T07:00:37.641274Z","shell.execute_reply":"2026-02-16T07:00:37.644034Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"warmup_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lr)\n\nbest_acc = 0\nbest_auc = 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:00:45.237467Z","iopub.execute_input":"2026-02-16T07:00:45.237960Z","iopub.status.idle":"2026-02-16T07:00:45.241703Z","shell.execute_reply.started":"2026-02-16T07:00:45.237923Z","shell.execute_reply":"2026-02-16T07:00:45.240950Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# ---------------------------\n# Training Loop\n# ---------------------------\nprint(\"Starting Training with Warmup...\\n\")\n\nfor epoch in range(NUM_EPOCHS):\n    # ===== TRAINING PHASE =====\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n    for images, labels in pbar:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images).squeeze()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        preds = (torch.sigmoid(outputs) > 0.5).float()\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        # Update progress bar\n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n    train_acc = 100 * correct / total\n    avg_train_loss = train_loss / len(train_loader)\n\n    # ===== VALIDATION PHASE =====\n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\"):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images).squeeze()\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            \n            probs = torch.sigmoid(outputs)\n            preds = (probs > 0.5).float()\n\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n            all_preds.extend(probs.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    test_acc = 100 * correct / total\n    avg_val_loss = val_loss / len(test_loader)\n    auc = roc_auc_score(all_labels, all_preds)\n\n    # Learning rate step\n    if epoch < WARMUP_EPOCHS:\n        warmup_scheduler.step()\n    else:\n        main_scheduler.step()\n    \n    current_lr = optimizer.param_groups[0]['lr']\n\n    # ===== PRINT RESULTS =====\n    print(f\"\\n{'='*60}\")\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n    print(f\"{'='*60}\")\n    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss:   {avg_val_loss:.4f} | Val Acc:   {test_acc:.2f}%\")\n    print(f\"AUC Score:  {auc:.4f}\")\n    print(f\"LR: {current_lr:.6f} {'[Warmup]' if epoch < WARMUP_EPOCHS else '[Main]'}\")\n\n    # Save best model\n    if test_acc > best_acc or (test_acc == best_acc and auc > best_auc):\n        best_acc = test_acc\n        best_auc = auc\n        torch.save(model.state_dict(), \"/kaggle/working/best_optimized_cnn.pth\")\n        print(f\"✓ Best model saved! (Acc: {best_acc:.2f}%, AUC: {best_auc:.4f})\")\n\n    print(f\"{'='*60}\\n\")\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Training Complete!\")\nprint(f\"Best Validation Accuracy: {best_acc:.2f}%\")\nprint(f\"Best AUC Score: {best_auc:.4f}\")\nprint(f\"{'='*60}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:00:57.361487Z","iopub.execute_input":"2026-02-16T07:00:57.361997Z","iopub.status.idle":"2026-02-16T07:11:59.242445Z","shell.execute_reply.started":"2026-02-16T07:00:57.361958Z","shell.execute_reply":"2026-02-16T07:11:59.241511Z"}},"outputs":[{"name":"stdout","text":"Starting Training with Warmup...\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/35 [Train]: 100%|██████████| 44/44 [00:18<00:00,  2.36it/s, loss=0.6929]\nEpoch 1/35 [Val]: 100%|██████████| 21/21 [00:03<00:00,  6.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 1/35\n============================================================\nTrain Loss: 0.6296 | Train Acc: 66.00%\nVal Loss:   0.5554 | Val Acc:   76.88%\nAUC Score:  0.8174\nLR: 0.000800 [Warmup]\n✓ Best model saved! (Acc: 76.88%, AUC: 0.8174)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.67it/s, loss=0.6066]\nEpoch 2/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 2/35\n============================================================\nTrain Loss: 0.5986 | Train Acc: 67.71%\nVal Loss:   0.7172 | Val Acc:   61.60%\nAUC Score:  0.7209\nLR: 0.001200 [Warmup]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.69it/s, loss=0.6026]\nEpoch 3/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 3/35\n============================================================\nTrain Loss: 0.6030 | Train Acc: 68.32%\nVal Loss:   0.7389 | Val Acc:   64.21%\nAUC Score:  0.7934\nLR: 0.001600 [Warmup]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.59it/s, loss=0.5337]\nEpoch 4/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 4/35\n============================================================\nTrain Loss: 0.5871 | Train Acc: 70.03%\nVal Loss:   0.4992 | Val Acc:   76.80%\nAUC Score:  0.8371\nLR: 0.002000 [Warmup]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.61it/s, loss=0.5199]\nEpoch 5/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 5/35\n============================================================\nTrain Loss: 0.5533 | Train Acc: 70.96%\nVal Loss:   0.6976 | Val Acc:   69.20%\nAUC Score:  0.8183\nLR: 0.002000 [Warmup]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.66it/s, loss=0.3673]\nEpoch 6/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 6/35\n============================================================\nTrain Loss: 0.5184 | Train Acc: 75.87%\nVal Loss:   0.5977 | Val Acc:   68.28%\nAUC Score:  0.8078\nLR: 0.001995 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.72it/s, loss=0.4752]\nEpoch 7/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 7/35\n============================================================\nTrain Loss: 0.4889 | Train Acc: 76.98%\nVal Loss:   0.4985 | Val Acc:   74.73%\nAUC Score:  0.8334\nLR: 0.001978 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.68it/s, loss=0.4380]\nEpoch 8/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 8/35\n============================================================\nTrain Loss: 0.4503 | Train Acc: 79.15%\nVal Loss:   0.5422 | Val Acc:   73.04%\nAUC Score:  0.8599\nLR: 0.001951 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.68it/s, loss=0.3184]\nEpoch 9/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 9/35\n============================================================\nTrain Loss: 0.4510 | Train Acc: 79.83%\nVal Loss:   0.4435 | Val Acc:   76.96%\nAUC Score:  0.8788\nLR: 0.001914 [Main]\n✓ Best model saved! (Acc: 76.96%, AUC: 0.8788)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.68it/s, loss=0.4707]\nEpoch 10/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 10/35\n============================================================\nTrain Loss: 0.4393 | Train Acc: 80.79%\nVal Loss:   0.5747 | Val Acc:   78.03%\nAUC Score:  0.8817\nLR: 0.001866 [Main]\n✓ Best model saved! (Acc: 78.03%, AUC: 0.8817)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.79it/s, loss=0.5700]\nEpoch 11/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 11/35\n============================================================\nTrain Loss: 0.4451 | Train Acc: 81.15%\nVal Loss:   0.5424 | Val Acc:   72.12%\nAUC Score:  0.8464\nLR: 0.001809 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.75it/s, loss=0.3943]\nEpoch 12/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 12/35\n============================================================\nTrain Loss: 0.4115 | Train Acc: 82.61%\nVal Loss:   0.5027 | Val Acc:   75.19%\nAUC Score:  0.8822\nLR: 0.001743 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.77it/s, loss=0.4637]\nEpoch 13/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 13/35\n============================================================\nTrain Loss: 0.3953 | Train Acc: 81.65%\nVal Loss:   0.4696 | Val Acc:   77.65%\nAUC Score:  0.8782\nLR: 0.001669 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.78it/s, loss=0.3869]\nEpoch 14/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 14/35\n============================================================\nTrain Loss: 0.3843 | Train Acc: 83.29%\nVal Loss:   0.4743 | Val Acc:   79.26%\nAUC Score:  0.8762\nLR: 0.001588 [Main]\n✓ Best model saved! (Acc: 79.26%, AUC: 0.8762)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.80it/s, loss=0.3652]\nEpoch 15/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 15/35\n============================================================\nTrain Loss: 0.3764 | Train Acc: 83.21%\nVal Loss:   0.3894 | Val Acc:   81.49%\nAUC Score:  0.9001\nLR: 0.001500 [Main]\n✓ Best model saved! (Acc: 81.49%, AUC: 0.9001)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.75it/s, loss=0.3385]\nEpoch 16/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 16/35\n============================================================\nTrain Loss: 0.3449 | Train Acc: 85.00%\nVal Loss:   0.5843 | Val Acc:   76.04%\nAUC Score:  0.8778\nLR: 0.001407 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.79it/s, loss=0.3179]\nEpoch 17/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 17/35\n============================================================\nTrain Loss: 0.3471 | Train Acc: 85.17%\nVal Loss:   0.4377 | Val Acc:   81.03%\nAUC Score:  0.9035\nLR: 0.001309 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.74it/s, loss=0.3303]\nEpoch 18/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 18/35\n============================================================\nTrain Loss: 0.3393 | Train Acc: 85.71%\nVal Loss:   0.4374 | Val Acc:   80.88%\nAUC Score:  0.9084\nLR: 0.001208 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.80it/s, loss=0.3210]\nEpoch 19/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 19/35\n============================================================\nTrain Loss: 0.3264 | Train Acc: 85.82%\nVal Loss:   0.4122 | Val Acc:   82.49%\nAUC Score:  0.9052\nLR: 0.001105 [Main]\n✓ Best model saved! (Acc: 82.49%, AUC: 0.9052)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.77it/s, loss=0.2278]\nEpoch 20/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 20/35\n============================================================\nTrain Loss: 0.2952 | Train Acc: 87.67%\nVal Loss:   0.3761 | Val Acc:   82.10%\nAUC Score:  0.9068\nLR: 0.001000 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.79it/s, loss=0.3200]\nEpoch 21/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 21/35\n============================================================\nTrain Loss: 0.3076 | Train Acc: 86.96%\nVal Loss:   0.3987 | Val Acc:   82.49%\nAUC Score:  0.9057\nLR: 0.000896 [Main]\n✓ Best model saved! (Acc: 82.49%, AUC: 0.9057)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.75it/s, loss=0.2337]\nEpoch 22/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 22/35\n============================================================\nTrain Loss: 0.3174 | Train Acc: 86.53%\nVal Loss:   0.3721 | Val Acc:   82.41%\nAUC Score:  0.9239\nLR: 0.000793 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.76it/s, loss=0.3374]\nEpoch 23/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 23/35\n============================================================\nTrain Loss: 0.2728 | Train Acc: 88.42%\nVal Loss:   0.3849 | Val Acc:   82.18%\nAUC Score:  0.9179\nLR: 0.000692 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.76it/s, loss=0.2697]\nEpoch 24/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 24/35\n============================================================\nTrain Loss: 0.2449 | Train Acc: 89.74%\nVal Loss:   0.3711 | Val Acc:   83.49%\nAUC Score:  0.9168\nLR: 0.000594 [Main]\n✓ Best model saved! (Acc: 83.49%, AUC: 0.9168)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/35 [Train]: 100%|██████████| 44/44 [00:17<00:00,  2.45it/s, loss=0.3086]\nEpoch 25/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 25/35\n============================================================\nTrain Loss: 0.2545 | Train Acc: 89.02%\nVal Loss:   0.4334 | Val Acc:   82.26%\nAUC Score:  0.9214\nLR: 0.000501 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.70it/s, loss=0.2560]\nEpoch 26/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 26/35\n============================================================\nTrain Loss: 0.2451 | Train Acc: 89.70%\nVal Loss:   0.4167 | Val Acc:   81.95%\nAUC Score:  0.9094\nLR: 0.000413 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.74it/s, loss=0.3578]\nEpoch 27/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 27/35\n============================================================\nTrain Loss: 0.2244 | Train Acc: 90.56%\nVal Loss:   0.4388 | Val Acc:   82.49%\nAUC Score:  0.9225\nLR: 0.000332 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.73it/s, loss=0.2347]\nEpoch 28/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 28/35\n============================================================\nTrain Loss: 0.2244 | Train Acc: 90.56%\nVal Loss:   0.3481 | Val Acc:   85.25%\nAUC Score:  0.9291\nLR: 0.000258 [Main]\n✓ Best model saved! (Acc: 85.25%, AUC: 0.9291)\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/35 [Train]: 100%|██████████| 44/44 [00:15<00:00,  2.76it/s, loss=0.2210]\nEpoch 29/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  8.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 29/35\n============================================================\nTrain Loss: 0.2092 | Train Acc: 91.30%\nVal Loss:   0.4049 | Val Acc:   83.95%\nAUC Score:  0.9279\nLR: 0.000192 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.68it/s, loss=0.2684]\nEpoch 30/35 [Val]: 100%|██████████| 21/21 [00:03<00:00,  6.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 30/35\n============================================================\nTrain Loss: 0.2141 | Train Acc: 91.16%\nVal Loss:   0.4163 | Val Acc:   83.64%\nAUC Score:  0.9206\nLR: 0.000135 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.64it/s, loss=0.2879]\nEpoch 31/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  7.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 31/35\n============================================================\nTrain Loss: 0.2062 | Train Acc: 91.38%\nVal Loss:   0.3706 | Val Acc:   84.95%\nAUC Score:  0.9293\nLR: 0.000087 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.61it/s, loss=0.2556]\nEpoch 32/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  7.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 32/35\n============================================================\nTrain Loss: 0.1856 | Train Acc: 92.09%\nVal Loss:   0.4395 | Val Acc:   83.33%\nAUC Score:  0.9217\nLR: 0.000050 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.64it/s, loss=0.2158]\nEpoch 33/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  7.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 33/35\n============================================================\nTrain Loss: 0.1863 | Train Acc: 92.05%\nVal Loss:   0.4332 | Val Acc:   83.72%\nAUC Score:  0.9221\nLR: 0.000023 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.67it/s, loss=0.1894]\nEpoch 34/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  7.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 34/35\n============================================================\nTrain Loss: 0.1961 | Train Acc: 91.87%\nVal Loss:   0.4175 | Val Acc:   83.95%\nAUC Score:  0.9262\nLR: 0.000006 [Main]\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/35 [Train]: 100%|██████████| 44/44 [00:16<00:00,  2.62it/s, loss=0.1742]\nEpoch 35/35 [Val]: 100%|██████████| 21/21 [00:02<00:00,  7.80it/s]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 35/35\n============================================================\nTrain Loss: 0.1839 | Train Acc: 91.87%\nVal Loss:   0.4078 | Val Acc:   84.64%\nAUC Score:  0.9261\nLR: 0.000001 [Main]\n============================================================\n\n\n============================================================\nTraining Complete!\nBest Validation Accuracy: 85.25%\nBest AUC Score: 0.9291\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# ---------------------------\n# ONNX Export\n# ---------------------------\nprint(\"Exporting model to ONNX format...\")\n\nonnx_path = \"/kaggle/working/optimized_antispoof_cnn.onnx\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:13:18.740228Z","iopub.execute_input":"2026-02-16T07:13:18.740814Z","iopub.status.idle":"2026-02-16T07:13:18.744835Z","shell.execute_reply.started":"2026-02-16T07:13:18.740780Z","shell.execute_reply":"2026-02-16T07:13:18.744266Z"}},"outputs":[{"name":"stdout","text":"Exporting model to ONNX format...\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Load best model\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_optimized_cnn.pth\"))\nmodel.eval()\n\ndummy_input = torch.randn(1, 3, 224, 224).to(device)\n\ntorch.onnx.export(\n    model,\n    dummy_input,\n    onnx_path,\n    export_params=True,\n    opset_version=13,\n    do_constant_folding=True,\n    input_names=[\"input\"],\n    output_names=[\"output\"],\n    dynamic_axes={\n        \"input\": {0: \"batch_size\"},\n        \"output\": {0: \"batch_size\"}\n    }\n)\n\nprint(f\"✓ ONNX model exported to: {onnx_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:13:27.107530Z","iopub.execute_input":"2026-02-16T07:13:27.108118Z","iopub.status.idle":"2026-02-16T07:13:28.221327Z","shell.execute_reply.started":"2026-02-16T07:13:27.108092Z","shell.execute_reply":"2026-02-16T07:13:28.220600Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2426272916.py:7: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n  torch.onnx.export(\n","output_type":"stream"},{"name":"stdout","text":"✓ ONNX model exported to: /kaggle/working/optimized_antispoof_cnn.onnx\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# ---------------------------\n# Final Evaluation\n# ---------------------------\nprint(\"\\nRunning final evaluation on test set...\")\n\nmodel.eval()\ncorrect = 0\ntotal = 0\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images).squeeze()\n        probs = torch.sigmoid(outputs)\n        preds = (probs > 0.5).float()\n\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        all_preds.extend(probs.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nfinal_acc = 100 * correct / total\nfinal_auc = roc_auc_score(all_labels, all_preds)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"FINAL TEST RESULTS\")\nprint(f\"{'='*60}\")\nprint(f\"Accuracy: {final_acc:.2f}%\")\nprint(f\"AUC Score: {final_auc:.4f}\")\nprint(f\"{'='*60}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:14:11.960051Z","iopub.execute_input":"2026-02-16T07:14:11.960851Z","iopub.status.idle":"2026-02-16T07:14:15.019490Z","shell.execute_reply.started":"2026-02-16T07:14:11.960820Z","shell.execute_reply":"2026-02-16T07:14:15.018688Z"}},"outputs":[{"name":"stdout","text":"\nRunning final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [00:03<00:00,  6.91it/s]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nFINAL TEST RESULTS\n============================================================\nAccuracy: 85.25%\nAUC Score: 0.9291\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":47}]}