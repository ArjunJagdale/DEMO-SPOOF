{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14851424,"sourceType":"datasetVersion","datasetId":9499335}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q timm onnxruntime onnxscript","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:09:07.859845Z","iopub.execute_input":"2026-02-16T19:09:07.860305Z","iopub.status.idle":"2026-02-16T19:09:14.799171Z","shell.execute_reply.started":"2026-02-16T19:09:07.860280Z","shell.execute_reply":"2026-02-16T19:09:14.798396Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:09:22.736394Z","iopub.execute_input":"2026-02-16T19:09:22.736891Z","iopub.status.idle":"2026-02-16T19:09:30.709545Z","shell.execute_reply.started":"2026-02-16T19:09:22.736839Z","shell.execute_reply":"2026-02-16T19:09:30.708779Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"TRAIN_REAL   = \"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/train/real\"\nTRAIN_ATTACK = \"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/train/attack\"\nTEST_REAL    = \"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/test/real\"\nTEST_ATTACK  = \"/kaggle/input/datasets/lightvvcx/full-dataset-frames/FULL_DATASET_FRAMES/test/attack\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:09:36.250851Z","iopub.execute_input":"2026-02-16T19:09:36.251571Z","iopub.status.idle":"2026-02-16T19:09:36.255241Z","shell.execute_reply.started":"2026-02-16T19:09:36.251543Z","shell.execute_reply":"2026-02-16T19:09:36.254473Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"BATCH_SIZE = 32\nLEARNING_RATE = 1e-3\nWEIGHT_DECAY = 1e-4\nEPOCHS = 50\nWARMUP_EPOCHS = 5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:09:43.215845Z","iopub.execute_input":"2026-02-16T19:09:43.216169Z","iopub.status.idle":"2026-02-16T19:09:43.220257Z","shell.execute_reply.started":"2026-02-16T19:09:43.216126Z","shell.execute_reply":"2026-02-16T19:09:43.219645Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:09:52.806042Z","iopub.execute_input":"2026-02-16T19:09:52.806794Z","iopub.status.idle":"2026-02-16T19:09:52.867948Z","shell.execute_reply.started":"2026-02-16T19:09:52.806757Z","shell.execute_reply":"2026-02-16T19:09:52.867061Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# DATA TRANSFORMS\n# ============================================================================\n\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n    transforms.RandomRotation(15),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.2, scale=(0.02, 0.15))\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:00.081264Z","iopub.execute_input":"2026-02-16T19:10:00.081754Z","iopub.status.idle":"2026-02-16T19:10:00.087437Z","shell.execute_reply.started":"2026-02-16T19:10:00.081721Z","shell.execute_reply":"2026-02-16T19:10:00.086678Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# DATASET\n# ============================================================================\n\nclass AntispoofDataset(Dataset):\n    def __init__(self, real_dir, attack_dir, transform=None):\n        self.samples = []\n        self.transform = transform\n        \n        for person_id in os.listdir(real_dir):\n            person_path = os.path.join(real_dir, person_id)\n            if os.path.isdir(person_path):\n                for img_name in os.listdir(person_path):\n                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        self.samples.append((os.path.join(person_path, img_name), 1.0))  # Real = 1\n        \n        for person_id in os.listdir(attack_dir):\n            person_path = os.path.join(attack_dir, person_id)\n            if os.path.isdir(person_path):\n                for img_name in os.listdir(person_path):\n                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        self.samples.append((os.path.join(person_path, img_name), 0.0))  # Attack = 0\n        \n        real_count = sum(1 for _, label in self.samples if label == 1.0)\n        attack_count = len(self.samples) - real_count\n        print(f\"Loaded {len(self.samples)} frames - Real: {real_count} | Attack: {attack_count}\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, torch.tensor(label, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:08.880503Z","iopub.execute_input":"2026-02-16T19:10:08.881030Z","iopub.status.idle":"2026-02-16T19:10:08.888481Z","shell.execute_reply.started":"2026-02-16T19:10:08.881003Z","shell.execute_reply":"2026-02-16T19:10:08.887738Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = AntispoofDataset(TRAIN_REAL, TRAIN_ATTACK, train_transform)\ntest_dataset = AntispoofDataset(TEST_REAL, TEST_ATTACK, test_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:16.635569Z","iopub.execute_input":"2026-02-16T19:10:16.635855Z","iopub.status.idle":"2026-02-16T19:10:17.887941Z","shell.execute_reply.started":"2026-02-16T19:10:16.635831Z","shell.execute_reply":"2026-02-16T19:10:17.887098Z"}},"outputs":[{"name":"stdout","text":"Loaded 2806 frames - Real: 1333 | Attack: 1473\nLoaded 1302 frames - Real: 637 | Attack: 665\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:26.310584Z","iopub.execute_input":"2026-02-16T19:10:26.311288Z","iopub.status.idle":"2026-02-16T19:10:26.315242Z","shell.execute_reply.started":"2026-02-16T19:10:26.311263Z","shell.execute_reply":"2026-02-16T19:10:26.314520Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ============================================================================\n# LIGHTWEIGHT MODEL WITH TEXTURE BRANCH\n# ============================================================================\n\nclass SEBlock(nn.Module):\n    \"\"\"Squeeze-and-Excitation block\"\"\"\n    def __init__(self, channels, reduction=16):\n        super().__init__()\n        self.squeeze = nn.AdaptiveAvgPool2d(1)\n        self.excitation = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.squeeze(x).view(b, c)\n        y = self.excitation(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:36.740528Z","iopub.execute_input":"2026-02-16T19:10:36.741044Z","iopub.status.idle":"2026-02-16T19:10:36.746546Z","shell.execute_reply.started":"2026-02-16T19:10:36.741018Z","shell.execute_reply":"2026-02-16T19:10:36.745861Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class TextureBlock(nn.Module):\n    \"\"\"Multi-scale texture extraction\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.branch_a = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels // 2, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels // 2),\n            nn.ReLU(inplace=True)\n        )\n        self.branch_b = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels // 2, 5, padding=2, bias=False),\n            nn.BatchNorm2d(out_channels // 2),\n            nn.ReLU(inplace=True)\n        )\n        self.se = SEBlock(out_channels)\n    \n    def forward(self, x):\n        a = self.branch_a(x)\n        b = self.branch_b(x)\n        out = torch.cat([a, b], dim=1)\n        out = self.se(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:45.051238Z","iopub.execute_input":"2026-02-16T19:10:45.051539Z","iopub.status.idle":"2026-02-16T19:10:45.057385Z","shell.execute_reply.started":"2026-02-16T19:10:45.051517Z","shell.execute_reply":"2026-02-16T19:10:45.056634Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    \"\"\"Residual block with dilation\"\"\"\n    def __init__(self, in_channels, out_channels, dilation=2, dropout=0.3):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(dropout)\n        )\n        self.se = SEBlock(out_channels)\n        \n        self.skip = nn.Sequential()\n        if in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        out = self.conv(x)\n        out = self.se(out)\n        out = out + self.skip(x)\n        return F.relu(out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:10:59.120879Z","iopub.execute_input":"2026-02-16T19:10:59.121196Z","iopub.status.idle":"2026-02-16T19:10:59.126965Z","shell.execute_reply.started":"2026-02-16T19:10:59.121143Z","shell.execute_reply":"2026-02-16T19:10:59.126431Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class AntispoofCNN(nn.Module):\n    \"\"\"\n    Lightweight Anti-spoofing CNN with Texture Branch\n    Binary classification: Single logit output\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        \n        # Stem\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, 32, 5, stride=2, padding=2, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True)\n        )\n        \n        # Multi-scale texture extraction\n        self.texture_block = TextureBlock(32, 64)\n        self.pool1 = nn.AvgPool2d(2, 2)\n        \n        # Main backbone\n        self.block2 = ResidualBlock(64, 128, dilation=2, dropout=0.3)\n        self.pool2 = nn.AvgPool2d(2, 2)\n        \n        self.block3 = ResidualBlock(128, 256, dilation=2, dropout=0.4)\n        self.pool3 = nn.AvgPool2d(2, 2)\n        \n        self.block4 = ResidualBlock(256, 512, dilation=2, dropout=0.5)\n        \n        # Specialized texture analysis branch (from block2)\n        self.texture_analyzer = nn.Sequential(\n            nn.Conv2d(128, 64, 3, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(64, 64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3)\n        )\n        \n        # Global pooling for main branch\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        \n        # Classifier: Combines main features + texture features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 + 64, 256),  # Main (512) + Texture (64)\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.4),\n            nn.Linear(128, 1)  # SINGLE LOGIT OUTPUT\n        )\n    \n    def forward(self, x):\n        x = self.stem(x)\n        x = self.texture_block(x)\n        x = self.pool1(x)\n        \n        x = self.block2(x)\n        texture_feat = self.texture_analyzer(x)  # Extract texture features\n        x = self.pool2(x)\n        \n        x = self.block3(x)\n        x = self.pool3(x)\n        x = self.block4(x)\n        \n        main_feat = self.global_pool(x).flatten(1)\n        \n        # Combine main + texture features\n        combined = torch.cat([main_feat, texture_feat], dim=1)\n        \n        # Single logit output\n        output = self.classifier(combined)\n        \n        return output.squeeze()  # Remove extra dimensions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:11:10.535535Z","iopub.execute_input":"2026-02-16T19:11:10.535793Z","iopub.status.idle":"2026-02-16T19:11:10.545521Z","shell.execute_reply.started":"2026-02-16T19:11:10.535771Z","shell.execute_reply":"2026-02-16T19:11:10.544866Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model = AntispoofCNN().to(device)\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"\\nModel parameters: {total_params:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:11:18.180450Z","iopub.execute_input":"2026-02-16T19:11:18.181095Z","iopub.status.idle":"2026-02-16T19:11:18.364607Z","shell.execute_reply.started":"2026-02-16T19:11:18.181069Z","shell.execute_reply":"2026-02-16T19:11:18.363840Z"}},"outputs":[{"name":"stdout","text":"\nModel parameters: 2,100,577\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================================\n# TRAINING SETUP - BCE LOSS FOR BINARY CLASSIFICATION\n# ============================================================================\n\n# Calculate class weights for imbalance\ntrain_real_count = sum(1 for _, label in train_dataset.samples if label == 1.0)\ntrain_attack_count = len(train_dataset.samples) - train_real_count\npos_weight = torch.tensor([train_attack_count / train_real_count]).to(device)\n\nprint(f\"\\nClass balance - Real: {train_real_count}, Attack: {train_attack_count}\")\nprint(f\"Positive weight (for Real class): {pos_weight.item():.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:14:37.840820Z","iopub.execute_input":"2026-02-16T19:14:37.841640Z","iopub.status.idle":"2026-02-16T19:14:37.847408Z","shell.execute_reply.started":"2026-02-16T19:14:37.841612Z","shell.execute_reply":"2026-02-16T19:14:37.846648Z"}},"outputs":[{"name":"stdout","text":"\nClass balance - Real: 1333, Attack: 1473\nPositive weight (for Real class): 1.105\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# BCE Loss with positive weight\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS)\n\n# Mixed precision\nscaler = torch.cuda.amp.GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:15:05.466053Z","iopub.execute_input":"2026-02-16T19:15:05.466655Z","iopub.status.idle":"2026-02-16T19:15:05.471432Z","shell.execute_reply.started":"2026-02-16T19:15:05.466628Z","shell.execute_reply":"2026-02-16T19:15:05.470686Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# ============================================================================\n# TRAINING FUNCTIONS\n# ============================================================================\n\ndef train_epoch(model, loader, criterion, optimizer, scaler):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(loader, desc='Training')\n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        \n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        \n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        \n        running_loss += loss.item()\n        preds = (torch.sigmoid(outputs) > 0.5).float()\n        total += labels.size(0)\n        correct += (preds == labels).sum().item()\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n    \n    return running_loss / len(loader), 100. * correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:15:13.870801Z","iopub.execute_input":"2026-02-16T19:15:13.871427Z","iopub.status.idle":"2026-02-16T19:15:13.878049Z","shell.execute_reply.started":"2026-02-16T19:15:13.871391Z","shell.execute_reply":"2026-02-16T19:15:13.877206Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def validate_with_metrics(model, loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    real_correct = 0\n    real_total = 0\n    attack_correct = 0\n    attack_total = 0\n    \n    all_probs = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(loader, desc='Validation'):\n            images, labels = images.to(device), labels.to(device)\n            \n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            probs = torch.sigmoid(outputs)\n            preds = (probs > 0.5).float()\n            \n            total += labels.size(0)\n            correct += (preds == labels).sum().item()\n            \n            # Per-class accuracy\n            real_mask = labels == 1.0\n            attack_mask = labels == 0.0\n            \n            real_total += real_mask.sum().item()\n            attack_total += attack_mask.sum().item()\n            \n            real_correct += (preds[real_mask] == labels[real_mask]).sum().item()\n            attack_correct += (preds[attack_mask] == labels[attack_mask]).sum().item()\n            \n            all_probs.extend(probs.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    val_loss = running_loss / len(loader)\n    val_acc = 100. * correct / total\n    real_acc = 100. * real_correct / real_total if real_total > 0 else 0\n    attack_acc = 100. * attack_correct / attack_total if attack_total > 0 else 0\n    auc = roc_auc_score(all_labels, all_probs)\n    \n    return val_loss, val_acc, real_acc, attack_acc, auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:15:24.170485Z","iopub.execute_input":"2026-02-16T19:15:24.170950Z","iopub.status.idle":"2026-02-16T19:15:24.178269Z","shell.execute_reply.started":"2026-02-16T19:15:24.170924Z","shell.execute_reply":"2026-02-16T19:15:24.177576Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# ============================================================================\n# TRAINING LOOP\n# ============================================================================\n\nbest_score = float('inf')\nbest_epoch = 0\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING - BINARY CLASSIFICATION (BCE LOSS)\")\nprint(\"=\"*60)\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    print(\"-\" * 60)\n    \n    # Warmup\n    if epoch < WARMUP_EPOCHS:\n        lr = LEARNING_RATE * (epoch + 1) / WARMUP_EPOCHS\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n    \n    # Train\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler)\n    \n    # Validate\n    val_loss, val_acc, real_acc, attack_acc, auc = validate_with_metrics(model, test_loader, criterion)\n    \n    # Update scheduler\n    if epoch >= WARMUP_EPOCHS:\n        scheduler.step()\n    \n    current_lr = optimizer.param_groups[0]['lr']\n    divergence = abs(real_acc - attack_acc)\n    \n    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n    print(f\"Real: {real_acc:.2f}% | Attack: {attack_acc:.2f}% | Divergence: {divergence:.2f}%\")\n    print(f\"AUC: {auc:.4f}\")\n    print(f\"Learning Rate: {current_lr:.6f}\")\n    \n    # Save best model (lowest divergence + highest accuracy)\n    score = divergence - val_acc\n    \n    if score < best_score:\n        best_score = score\n        best_epoch = epoch + 1\n        torch.save(model.state_dict(), \"/kaggle/working/best_optimized_cnn.pth\")\n        print(f\"✓ Best model saved! (Divergence: {divergence:.2f}%, Val Acc: {val_acc:.2f}%, AUC: {auc:.4f})\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"TRAINING COMPLETE - Best Epoch: {best_epoch}\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:15:36.970777Z","iopub.execute_input":"2026-02-16T19:15:36.971254Z","iopub.status.idle":"2026-02-16T19:30:14.379998Z","shell.execute_reply.started":"2026-02-16T19:15:36.971227Z","shell.execute_reply":"2026-02-16T19:30:14.379216Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTARTING TRAINING - BINARY CLASSIFICATION (BCE LOSS)\n============================================================\n\nEpoch 1/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:22<00:00,  3.98it/s, loss=0.6168, acc=65.11%]\nValidation: 100%|██████████| 41/41 [00:04<00:00,  8.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6638 | Train Acc: 65.11%\nVal Loss: 0.5774 | Val Acc: 74.58%\nReal: 88.85% | Attack: 60.90% | Divergence: 27.95%\nAUC: 0.8280\nLearning Rate: 0.000200\n✓ Best model saved! (Divergence: 27.95%, Val Acc: 74.58%, AUC: 0.8280)\n\nEpoch 2/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.86it/s, loss=0.6626, acc=66.82%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6511 | Train Acc: 66.82%\nVal Loss: 0.5348 | Val Acc: 79.80%\nReal: 91.52% | Attack: 68.57% | Divergence: 22.95%\nAUC: 0.8564\nLearning Rate: 0.000400\n✓ Best model saved! (Divergence: 22.95%, Val Acc: 79.80%, AUC: 0.8564)\n\nEpoch 3/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.80it/s, loss=0.7536, acc=65.32%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6676 | Train Acc: 65.32%\nVal Loss: 0.6146 | Val Acc: 67.43%\nReal: 43.49% | Attack: 90.38% | Divergence: 46.89%\nAUC: 0.8223\nLearning Rate: 0.000600\n\nEpoch 4/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.85it/s, loss=0.6588, acc=67.21%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6559 | Train Acc: 67.21%\nVal Loss: 0.6064 | Val Acc: 74.58%\nReal: 63.42% | Attack: 85.26% | Divergence: 21.84%\nAUC: 0.8223\nLearning Rate: 0.000800\n\nEpoch 5/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.94it/s, loss=0.4932, acc=67.14%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6510 | Train Acc: 67.14%\nVal Loss: 0.6354 | Val Acc: 67.20%\nReal: 93.09% | Attack: 42.41% | Divergence: 50.69%\nAUC: 0.8076\nLearning Rate: 0.001000\n\nEpoch 6/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.89it/s, loss=0.5889, acc=70.21%]\nValidation: 100%|██████████| 41/41 [00:01<00:00, 20.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6116 | Train Acc: 70.21%\nVal Loss: 0.5467 | Val Acc: 74.88%\nReal: 80.53% | Attack: 69.47% | Divergence: 11.06%\nAUC: 0.8260\nLearning Rate: 0.000999\n✓ Best model saved! (Divergence: 11.06%, Val Acc: 74.88%, AUC: 0.8260)\n\nEpoch 7/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.90it/s, loss=0.4930, acc=70.81%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6148 | Train Acc: 70.81%\nVal Loss: 0.5506 | Val Acc: 73.73%\nReal: 58.56% | Attack: 88.27% | Divergence: 29.71%\nAUC: 0.8568\nLearning Rate: 0.000995\n\nEpoch 8/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.92it/s, loss=0.5402, acc=71.35%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6063 | Train Acc: 71.35%\nVal Loss: 0.5399 | Val Acc: 75.96%\nReal: 72.06% | Attack: 79.70% | Divergence: 7.64%\nAUC: 0.8468\nLearning Rate: 0.000989\n✓ Best model saved! (Divergence: 7.64%, Val Acc: 75.96%, AUC: 0.8468)\n\nEpoch 9/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.91it/s, loss=0.9979, acc=71.77%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5952 | Train Acc: 71.77%\nVal Loss: 0.5010 | Val Acc: 77.50%\nReal: 74.73% | Attack: 80.15% | Divergence: 5.43%\nAUC: 0.8596\nLearning Rate: 0.000981\n✓ Best model saved! (Divergence: 5.43%, Val Acc: 77.50%, AUC: 0.8596)\n\nEpoch 10/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.86it/s, loss=0.5330, acc=73.73%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5667 | Train Acc: 73.73%\nVal Loss: 0.6338 | Val Acc: 71.74%\nReal: 50.55% | Attack: 92.03% | Divergence: 41.48%\nAUC: 0.8605\nLearning Rate: 0.000970\n\nEpoch 11/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  6.00it/s, loss=0.6621, acc=72.81%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5852 | Train Acc: 72.81%\nVal Loss: 0.6291 | Val Acc: 74.73%\nReal: 56.51% | Attack: 92.18% | Divergence: 35.67%\nAUC: 0.8295\nLearning Rate: 0.000957\n\nEpoch 12/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.84it/s, loss=0.5544, acc=73.56%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5763 | Train Acc: 73.56%\nVal Loss: 0.5652 | Val Acc: 74.27%\nReal: 83.99% | Attack: 64.96% | Divergence: 19.03%\nAUC: 0.8265\nLearning Rate: 0.000941\n\nEpoch 13/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.83it/s, loss=0.5010, acc=74.27%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5583 | Train Acc: 74.27%\nVal Loss: 0.4482 | Val Acc: 82.41%\nReal: 84.14% | Attack: 80.75% | Divergence: 3.39%\nAUC: 0.9056\nLearning Rate: 0.000924\n✓ Best model saved! (Divergence: 3.39%, Val Acc: 82.41%, AUC: 0.9056)\n\nEpoch 14/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.87it/s, loss=0.6976, acc=73.38%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5676 | Train Acc: 73.38%\nVal Loss: 0.5337 | Val Acc: 77.57%\nReal: 71.74% | Attack: 83.16% | Divergence: 11.42%\nAUC: 0.8552\nLearning Rate: 0.000905\n\nEpoch 15/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.82it/s, loss=0.5155, acc=73.56%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5505 | Train Acc: 73.56%\nVal Loss: 0.4803 | Val Acc: 79.11%\nReal: 86.66% | Attack: 71.88% | Divergence: 14.78%\nAUC: 0.8850\nLearning Rate: 0.000883\n\nEpoch 16/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.78it/s, loss=0.5505, acc=75.02%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5350 | Train Acc: 75.02%\nVal Loss: 0.5036 | Val Acc: 78.65%\nReal: 72.06% | Attack: 84.96% | Divergence: 12.91%\nAUC: 0.8610\nLearning Rate: 0.000860\n\nEpoch 17/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.81it/s, loss=0.3627, acc=75.37%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5356 | Train Acc: 75.37%\nVal Loss: 0.5376 | Val Acc: 69.59%\nReal: 92.62% | Attack: 47.52% | Divergence: 45.10%\nAUC: 0.8690\nLearning Rate: 0.000835\n\nEpoch 18/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.80it/s, loss=0.5326, acc=75.87%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5204 | Train Acc: 75.87%\nVal Loss: 0.5696 | Val Acc: 75.88%\nReal: 59.81% | Attack: 91.28% | Divergence: 31.47%\nAUC: 0.8704\nLearning Rate: 0.000808\n\nEpoch 19/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.81it/s, loss=0.3966, acc=77.26%]\nValidation: 100%|██████████| 41/41 [00:01<00:00, 20.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4971 | Train Acc: 77.26%\nVal Loss: 0.4647 | Val Acc: 78.26%\nReal: 67.03% | Attack: 89.02% | Divergence: 21.99%\nAUC: 0.9003\nLearning Rate: 0.000780\n\nEpoch 20/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.80it/s, loss=0.4424, acc=77.94%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 20.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4973 | Train Acc: 77.94%\nVal Loss: 0.4854 | Val Acc: 79.49%\nReal: 77.24% | Attack: 81.65% | Divergence: 4.42%\nAUC: 0.8698\nLearning Rate: 0.000750\n\nEpoch 21/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.62it/s, loss=0.9676, acc=76.76%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5086 | Train Acc: 76.76%\nVal Loss: 0.6199 | Val Acc: 74.04%\nReal: 59.18% | Attack: 88.27% | Divergence: 29.09%\nAUC: 0.8413\nLearning Rate: 0.000719\n\nEpoch 22/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.65it/s, loss=0.5777, acc=78.83%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 16.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4730 | Train Acc: 78.83%\nVal Loss: 0.4677 | Val Acc: 78.96%\nReal: 74.10% | Attack: 83.61% | Divergence: 9.51%\nAUC: 0.8849\nLearning Rate: 0.000687\n\nEpoch 23/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.76it/s, loss=0.2170, acc=78.37%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4785 | Train Acc: 78.37%\nVal Loss: 0.4692 | Val Acc: 81.87%\nReal: 70.17% | Attack: 93.08% | Divergence: 22.91%\nAUC: 0.9077\nLearning Rate: 0.000655\n\nEpoch 24/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.85it/s, loss=0.2538, acc=78.51%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4729 | Train Acc: 78.51%\nVal Loss: 0.4032 | Val Acc: 82.64%\nReal: 83.83% | Attack: 81.50% | Divergence: 2.33%\nAUC: 0.9145\nLearning Rate: 0.000621\n✓ Best model saved! (Divergence: 2.33%, Val Acc: 82.64%, AUC: 0.9145)\n\nEpoch 25/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.93it/s, loss=0.3116, acc=77.58%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4838 | Train Acc: 77.58%\nVal Loss: 0.4347 | Val Acc: 79.88%\nReal: 90.11% | Attack: 70.08% | Divergence: 20.03%\nAUC: 0.9015\nLearning Rate: 0.000587\n\nEpoch 26/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.74it/s, loss=0.3348, acc=79.08%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4702 | Train Acc: 79.08%\nVal Loss: 0.5199 | Val Acc: 79.72%\nReal: 64.21% | Attack: 94.59% | Divergence: 30.38%\nAUC: 0.9012\nLearning Rate: 0.000552\n\nEpoch 27/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.79it/s, loss=0.3331, acc=80.33%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4428 | Train Acc: 80.33%\nVal Loss: 0.4381 | Val Acc: 80.11%\nReal: 83.52% | Attack: 76.84% | Divergence: 6.67%\nAUC: 0.8956\nLearning Rate: 0.000517\n\nEpoch 28/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.93it/s, loss=0.4017, acc=78.01%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4629 | Train Acc: 78.01%\nVal Loss: 0.4325 | Val Acc: 83.18%\nReal: 76.14% | Attack: 89.92% | Divergence: 13.79%\nAUC: 0.9086\nLearning Rate: 0.000483\n\nEpoch 29/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.92it/s, loss=0.4583, acc=80.51%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4370 | Train Acc: 80.51%\nVal Loss: 0.4241 | Val Acc: 80.49%\nReal: 83.20% | Attack: 77.89% | Divergence: 5.31%\nAUC: 0.9054\nLearning Rate: 0.000448\n\nEpoch 30/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.74it/s, loss=0.5930, acc=80.11%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4517 | Train Acc: 80.11%\nVal Loss: 0.4594 | Val Acc: 81.72%\nReal: 77.24% | Attack: 86.02% | Divergence: 8.78%\nAUC: 0.8869\nLearning Rate: 0.000413\n\nEpoch 31/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.86it/s, loss=0.7663, acc=79.62%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4568 | Train Acc: 79.62%\nVal Loss: 0.4229 | Val Acc: 82.26%\nReal: 81.63% | Attack: 82.86% | Divergence: 1.22%\nAUC: 0.9037\nLearning Rate: 0.000379\n✓ Best model saved! (Divergence: 1.22%, Val Acc: 82.26%, AUC: 0.9037)\n\nEpoch 32/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.74it/s, loss=0.5760, acc=81.40%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4403 | Train Acc: 81.40%\nVal Loss: 0.5099 | Val Acc: 79.03%\nReal: 73.63% | Attack: 84.21% | Divergence: 10.58%\nAUC: 0.8821\nLearning Rate: 0.000345\n\nEpoch 33/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.72it/s, loss=0.2567, acc=80.97%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4404 | Train Acc: 80.97%\nVal Loss: 0.4930 | Val Acc: 78.34%\nReal: 74.73% | Attack: 81.80% | Divergence: 7.08%\nAUC: 0.8823\nLearning Rate: 0.000313\n\nEpoch 34/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.80it/s, loss=0.4947, acc=80.86%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4243 | Train Acc: 80.86%\nVal Loss: 0.5763 | Val Acc: 78.73%\nReal: 67.66% | Attack: 89.32% | Divergence: 21.66%\nAUC: 0.8762\nLearning Rate: 0.000281\n\nEpoch 35/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.74it/s, loss=0.3886, acc=80.61%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 16.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4305 | Train Acc: 80.61%\nVal Loss: 0.5156 | Val Acc: 80.41%\nReal: 73.63% | Attack: 86.92% | Divergence: 13.29%\nAUC: 0.8911\nLearning Rate: 0.000250\n\nEpoch 36/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.74it/s, loss=0.5082, acc=81.79%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4223 | Train Acc: 81.79%\nVal Loss: 0.4043 | Val Acc: 82.33%\nReal: 85.24% | Attack: 79.55% | Divergence: 5.69%\nAUC: 0.9124\nLearning Rate: 0.000220\n\nEpoch 37/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.77it/s, loss=0.4565, acc=83.54%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 20.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4030 | Train Acc: 83.54%\nVal Loss: 0.5278 | Val Acc: 77.88%\nReal: 71.90% | Attack: 83.61% | Divergence: 11.71%\nAUC: 0.8809\nLearning Rate: 0.000192\n\nEpoch 38/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.71it/s, loss=0.4293, acc=83.43%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3983 | Train Acc: 83.43%\nVal Loss: 0.5025 | Val Acc: 79.42%\nReal: 74.57% | Attack: 84.06% | Divergence: 9.49%\nAUC: 0.8858\nLearning Rate: 0.000165\n\nEpoch 39/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.86it/s, loss=0.3295, acc=81.65%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4080 | Train Acc: 81.65%\nVal Loss: 0.4982 | Val Acc: 79.88%\nReal: 74.25% | Attack: 85.26% | Divergence: 11.01%\nAUC: 0.8954\nLearning Rate: 0.000140\n\nEpoch 40/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.92it/s, loss=0.5079, acc=82.97%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3994 | Train Acc: 82.97%\nVal Loss: 0.4447 | Val Acc: 81.57%\nReal: 79.59% | Attack: 83.46% | Divergence: 3.87%\nAUC: 0.9064\nLearning Rate: 0.000117\n\nEpoch 41/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.83it/s, loss=0.3361, acc=83.57%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3799 | Train Acc: 83.57%\nVal Loss: 0.4695 | Val Acc: 81.26%\nReal: 80.85% | Attack: 81.65% | Divergence: 0.81%\nAUC: 0.8960\nLearning Rate: 0.000095\n\nEpoch 42/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.83it/s, loss=0.7062, acc=83.54%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 16.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3859 | Train Acc: 83.54%\nVal Loss: 0.4350 | Val Acc: 81.41%\nReal: 81.32% | Attack: 81.50% | Divergence: 0.19%\nAUC: 0.9071\nLearning Rate: 0.000076\n✓ Best model saved! (Divergence: 0.19%, Val Acc: 81.41%, AUC: 0.9071)\n\nEpoch 43/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.62it/s, loss=0.3979, acc=83.21%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3911 | Train Acc: 83.21%\nVal Loss: 0.4539 | Val Acc: 81.41%\nReal: 78.81% | Attack: 83.91% | Divergence: 5.10%\nAUC: 0.9016\nLearning Rate: 0.000059\n\nEpoch 44/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.84it/s, loss=0.6420, acc=83.14%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3930 | Train Acc: 83.14%\nVal Loss: 0.4390 | Val Acc: 81.80%\nReal: 80.69% | Attack: 82.86% | Divergence: 2.17%\nAUC: 0.9051\nLearning Rate: 0.000043\n\nEpoch 45/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.79it/s, loss=0.2150, acc=83.57%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3886 | Train Acc: 83.57%\nVal Loss: 0.4207 | Val Acc: 82.72%\nReal: 81.63% | Attack: 83.76% | Divergence: 2.13%\nAUC: 0.9139\nLearning Rate: 0.000030\n\nEpoch 46/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.92it/s, loss=0.3719, acc=83.43%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3855 | Train Acc: 83.43%\nVal Loss: 0.4619 | Val Acc: 81.03%\nReal: 76.92% | Attack: 84.96% | Divergence: 8.04%\nAUC: 0.9057\nLearning Rate: 0.000019\n\nEpoch 47/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.91it/s, loss=0.3206, acc=83.29%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3818 | Train Acc: 83.29%\nVal Loss: 0.4441 | Val Acc: 81.26%\nReal: 78.65% | Attack: 83.76% | Divergence: 5.11%\nAUC: 0.9091\nLearning Rate: 0.000011\n\nEpoch 48/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.90it/s, loss=0.2868, acc=83.18%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 19.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3867 | Train Acc: 83.18%\nVal Loss: 0.4273 | Val Acc: 81.34%\nReal: 81.32% | Attack: 81.35% | Divergence: 0.03%\nAUC: 0.9100\nLearning Rate: 0.000005\n✓ Best model saved! (Divergence: 0.03%, Val Acc: 81.34%, AUC: 0.9100)\n\nEpoch 49/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:14<00:00,  5.96it/s, loss=0.6411, acc=83.82%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 18.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3765 | Train Acc: 83.82%\nVal Loss: 0.4461 | Val Acc: 81.57%\nReal: 78.34% | Attack: 84.66% | Divergence: 6.33%\nAUC: 0.9089\nLearning Rate: 0.000001\n\nEpoch 50/50\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 88/88 [00:15<00:00,  5.82it/s, loss=0.3967, acc=83.50%]\nValidation: 100%|██████████| 41/41 [00:02<00:00, 17.72it/s]","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.3760 | Train Acc: 83.50%\nVal Loss: 0.4427 | Val Acc: 81.34%\nReal: 80.22% | Attack: 82.41% | Divergence: 2.19%\nAUC: 0.9059\nLearning Rate: 0.000000\n\n============================================================\nTRAINING COMPLETE - Best Epoch: 48\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# ============================================================================\n# FINAL EVALUATION\n# ============================================================================\n\nprint(\"\\n\\nEvaluating best model...\")\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_optimized_cnn.pth\"))\n_, val_acc, real_acc, attack_acc, auc = validate_with_metrics(model, test_loader, criterion)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"FINAL TEST RESULTS (BEST MODEL FROM EPOCH {best_epoch})\")\nprint(f\"{'='*60}\")\nprint(f\"Overall Accuracy: {val_acc:.2f}%\")\nprint(f\"Real Detection: {real_acc:.2f}%\")\nprint(f\"Attack Detection: {attack_acc:.2f}%\")\nprint(f\"Divergence: {abs(real_acc - attack_acc):.2f}%\")\nprint(f\"AUC Score: {auc:.4f}\")\nprint(f\"{'='*60}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:30:32.325841Z","iopub.execute_input":"2026-02-16T19:30:32.326391Z","iopub.status.idle":"2026-02-16T19:30:34.435698Z","shell.execute_reply.started":"2026-02-16T19:30:32.326357Z","shell.execute_reply":"2026-02-16T19:30:34.434947Z"}},"outputs":[{"name":"stdout","text":"\n\nEvaluating best model...\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 41/41 [00:02<00:00, 19.82it/s]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nFINAL TEST RESULTS (BEST MODEL FROM EPOCH 48)\n============================================================\nOverall Accuracy: 81.34%\nReal Detection: 81.32%\nAttack Detection: 81.35%\nDivergence: 0.03%\nAUC Score: 0.9100\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# ============================================================================\n# ONNX EXPORT\n# ============================================================================\n\nprint(\"\\n\\nExporting to ONNX...\")\ndummy_input = torch.randn(1, 3, 224, 224).to(device)\nonnx_path = \"/kaggle/working/optimized_antispoof_cnn.onnx\"\n\ntorch.onnx.export(\n    model, dummy_input, onnx_path,\n    export_params=True, opset_version=13, do_constant_folding=True,\n    input_names=[\"input\"], output_names=[\"output\"],\n    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n)\n\nprint(f\"✓ ONNX: {onnx_path}\")\nprint(f\"✓ PyTorch: /kaggle/working/best_optimized_cnn.pth\")\nprint(f\"\\n🎯 Complete! Model outputs SINGLE LOGIT for binary classification\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:30:46.461386Z","iopub.execute_input":"2026-02-16T19:30:46.461688Z","iopub.status.idle":"2026-02-16T19:30:47.090925Z","shell.execute_reply.started":"2026-02-16T19:30:46.461657Z","shell.execute_reply":"2026-02-16T19:30:47.090308Z"}},"outputs":[{"name":"stdout","text":"\n\nExporting to ONNX...\n✓ ONNX: /kaggle/working/optimized_antispoof_cnn.onnx\n✓ PyTorch: /kaggle/working/best_optimized_cnn.pth\n\n🎯 Complete! Model outputs SINGLE LOGIT for binary classification\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# ============================================================================\n# ONNX VERIFICATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFYING ONNX MODEL\")\nprint(\"=\"*60)\n\n# Install onnxruntime if needed\ntry:\n    import onnxruntime as ort\nexcept:\n    import subprocess\n    subprocess.check_call(['pip', 'install', 'onnxruntime', '--quiet'])\n    import onnxruntime as ort\n\n# Load ONNX model\nort_session = ort.InferenceSession(onnx_path)\nprint(f\"✓ ONNX model loaded\")\nprint(f\"  Inputs: {[i.name for i in ort_session.get_inputs()]}\")\nprint(f\"  Outputs: {[o.name for o in ort_session.get_outputs()]}\")\n\n# Test with random input\nprint(\"\\n1. Testing with random input...\")\ntest_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n\n# ONNX inference\nonnx_output = ort_session.run(None, {\"input\": test_input})[0]\n\n# PyTorch inference\nmodel.eval()\nwith torch.no_grad():\n    torch_output = model(torch.from_numpy(test_input).to(device)).cpu().numpy()\n\nprint(f\"ONNX output:    {onnx_output}\")\nprint(f\"PyTorch output: {torch_output}\")\nprint(f\"Difference:     {np.abs(onnx_output - torch_output).max():.6f}\")\n\nif np.abs(onnx_output - torch_output).max() < 1e-4:\n    print(\"✓ ONNX and PyTorch outputs MATCH (difference < 0.0001)\")\nelse:\n    print(\"✗ WARNING: ONNX and PyTorch outputs DIFFER significantly!\")\n\n# Test with actual test images\nprint(\"\\n2. Testing with actual test images...\")\nnum_test_samples = 5\ntest_samples = []\n\n# Get some real test images\nfor images, labels in test_loader:\n    test_samples.append((images[:num_test_samples], labels[:num_test_samples]))\n    break\n\nimages, labels = test_samples[0]\nimages_np = images.numpy()\n\n# ONNX predictions\nonnx_preds = []\nfor i in range(num_test_samples):\n    img = images_np[i:i+1]\n    onnx_out = ort_session.run(None, {\"input\": img})[0][0]\n    onnx_prob = 1 / (1 + np.exp(-onnx_out))\n    onnx_preds.append(onnx_prob)\n\n# PyTorch predictions\ntorch_preds = []\nmodel.eval()\nwith torch.no_grad():\n    for i in range(num_test_samples):\n        img = images[i:i+1].to(device)\n        torch_out = model(img).cpu().numpy()[0]\n        torch_prob = 1 / (1 + np.exp(-torch_out))\n        torch_preds.append(torch_prob)\n\n# Compare predictions\nprint(\"\\nSample predictions comparison:\")\nprint(f\"{'Label':<10} {'ONNX Prob':<15} {'PyTorch Prob':<15} {'Difference':<15}\")\nprint(\"-\" * 60)\nfor i in range(num_test_samples):\n    label_str = \"Real\" if labels[i] == 1.0 else \"Attack\"\n    diff = abs(onnx_preds[i] - torch_preds[i])\n    print(f\"{label_str:<10} {onnx_preds[i]:<15.4f} {torch_preds[i]:<15.4f} {diff:<15.6f}\")\n\navg_diff = np.mean([abs(o - t) for o, t in zip(onnx_preds, torch_preds)])\nprint(f\"\\nAverage probability difference: {avg_diff:.6f}\")\n\nif avg_diff < 0.01:\n    print(\"✓ ONNX model verified successfully!\")\nelse:\n    print(\"✗ WARNING: ONNX predictions differ from PyTorch!\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFICATION COMPLETE\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:40:52.116248Z","iopub.execute_input":"2026-02-16T19:40:52.116861Z","iopub.status.idle":"2026-02-16T19:40:52.624534Z","shell.execute_reply.started":"2026-02-16T19:40:52.116832Z","shell.execute_reply":"2026-02-16T19:40:52.623399Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nVERIFYING ONNX MODEL\n============================================================\n✓ ONNX model loaded\n  Inputs: ['input']\n  Outputs: ['output']\n\n1. Testing with random input...\nONNX output:    21.0582218170166\nPyTorch output: 21.058225631713867\nDifference:     0.000004\n✓ ONNX and PyTorch outputs MATCH (difference < 0.0001)\n\n2. Testing with actual test images...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/956573434.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0monnx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0monnx_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0monnx_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0monnx_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"],"ename":"IndexError","evalue":"too many indices for array: array is 0-dimensional, but 1 were indexed","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"# ============================================================================\n# ONNX VERIFICATION (FIXED)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFYING ONNX MODEL\")\nprint(\"=\"*60)\n\n# Install onnxruntime if needed\ntry:\n    import onnxruntime as ort\nexcept:\n    import subprocess\n    subprocess.check_call(['pip', 'install', 'onnxruntime', '--quiet'])\n    import onnxruntime as ort\n\n# Load ONNX model\nort_session = ort.InferenceSession(onnx_path)\nprint(f\"✓ ONNX model loaded\")\nprint(f\"  Inputs: {[i.name for i in ort_session.get_inputs()]}\")\nprint(f\"  Outputs: {[o.name for o in ort_session.get_outputs()]}\")\n\n# Test with random input\nprint(\"\\n1. Testing with random input...\")\ntest_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n\n# ONNX inference\nonnx_output = ort_session.run(None, {\"input\": test_input})[0]\nprint(f\"ONNX output shape: {onnx_output.shape}\")\n\n# PyTorch inference\nmodel.eval()\nwith torch.no_grad():\n    torch_output = model(torch.from_numpy(test_input).to(device)).cpu().numpy()\n\nprint(f\"ONNX output:    {onnx_output}\")\nprint(f\"PyTorch output: {torch_output}\")\nprint(f\"Difference:     {np.abs(onnx_output - torch_output).max():.6f}\")\n\nif np.abs(onnx_output - torch_output).max() < 1e-4:\n    print(\"✓ ONNX and PyTorch outputs MATCH (difference < 0.0001)\")\nelse:\n    print(\"✗ WARNING: ONNX and PyTorch outputs DIFFER significantly!\")\n\n# Test with actual test images\nprint(\"\\n2. Testing with actual test images...\")\nnum_test_samples = 5\ntest_samples = []\n\n# Get some real test images\nfor images, labels in test_loader:\n    test_samples.append((images[:num_test_samples], labels[:num_test_samples]))\n    break\n\nimages, labels = test_samples[0]\nimages_np = images.numpy()\n\n# ONNX predictions\nonnx_preds = []\nfor i in range(num_test_samples):\n    img = images_np[i:i+1]\n    onnx_out = ort_session.run(None, {\"input\": img})[0]\n    \n    # Handle different output shapes\n    if onnx_out.ndim == 0:  # Scalar\n        onnx_logit = float(onnx_out)\n    elif onnx_out.shape == (1,):  # Shape (1,)\n        onnx_logit = onnx_out[0]\n    else:  # Shape (1, 1) or other\n        onnx_logit = onnx_out.flatten()[0]\n    \n    onnx_prob = 1 / (1 + np.exp(-onnx_logit))\n    onnx_preds.append(onnx_prob)\n\n# PyTorch predictions\ntorch_preds = []\nmodel.eval()\nwith torch.no_grad():\n    for i in range(num_test_samples):\n        img = images[i:i+1].to(device)\n        torch_out = model(img).cpu().numpy()\n        \n        # Handle different output shapes\n        if torch_out.ndim == 0:\n            torch_logit = float(torch_out)\n        else:\n            torch_logit = torch_out.flatten()[0]\n        \n        torch_prob = 1 / (1 + np.exp(-torch_logit))\n        torch_preds.append(torch_prob)\n\n# Compare predictions\nprint(\"\\nSample predictions comparison:\")\nprint(f\"{'Label':<10} {'ONNX Prob':<15} {'PyTorch Prob':<15} {'Difference':<15}\")\nprint(\"-\" * 60)\nfor i in range(num_test_samples):\n    label_str = \"Real\" if labels[i] == 1.0 else \"Attack\"\n    diff = abs(onnx_preds[i] - torch_preds[i])\n    print(f\"{label_str:<10} {onnx_preds[i]:<15.4f} {torch_preds[i]:<15.4f} {diff:<15.6f}\")\n\navg_diff = np.mean([abs(o - t) for o, t in zip(onnx_preds, torch_preds)])\nprint(f\"\\nAverage probability difference: {avg_diff:.6f}\")\n\nif avg_diff < 0.01:\n    print(\"✓ ONNX model verified successfully!\")\nelse:\n    print(\"✗ WARNING: ONNX predictions differ from PyTorch!\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFICATION COMPLETE\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T19:41:33.896590Z","iopub.execute_input":"2026-02-16T19:41:33.897316Z","iopub.status.idle":"2026-02-16T19:41:34.405883Z","shell.execute_reply.started":"2026-02-16T19:41:33.897282Z","shell.execute_reply":"2026-02-16T19:41:34.404924Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nVERIFYING ONNX MODEL\n============================================================\n✓ ONNX model loaded\n  Inputs: ['input']\n  Outputs: ['output']\n\n1. Testing with random input...\nONNX output shape: ()\nONNX output:    21.19365882873535\nPyTorch output: 21.193660736083984\nDifference:     0.000002\n✓ ONNX and PyTorch outputs MATCH (difference < 0.0001)\n\n2. Testing with actual test images...\n\nSample predictions comparison:\nLabel      ONNX Prob       PyTorch Prob    Difference     \n------------------------------------------------------------\nReal       0.8358          0.8358          0.000000       \nReal       0.8827          0.8827          0.000000       \nReal       0.6714          0.6714          0.000000       \nReal       0.6794          0.6794          0.000000       \nReal       0.5353          0.5353          0.000002       \n\nAverage probability difference: 0.000000\n✓ ONNX model verified successfully!\n\n============================================================\nVERIFICATION COMPLETE\n============================================================\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}